{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49806132",
   "metadata": {},
   "source": [
    "# Exploring text-embeddings-inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114644d",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use open source embedding model from text-embeddings-inference server in your RAG pipelines.\n",
    "\n",
    "We are implementing two approaches:\n",
    "\n",
    "1. Install text-embeddings-inference server on a local CPU, run evaluations to compare performance between two embedding models: inference server's bge-large-en-v1.5 vs OpenAI's text-embedding-ada-002.\n",
    "\n",
    "2. Install text-embeddings-inference server on an AWS GPU EC2 instance, instance type g5.xlarge. We again run the evaluations to compare performance between the embedding models from the inference server and that from OpenAI.\n",
    "\n",
    "* LLM is gpt-3.5-turbo \n",
    "* Use embedding model from inference server\n",
    "* Use embedding model from OpenAI\n",
    "* Apply EDD to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e3fa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index==0.8.48 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (0.8.48)\n",
      "Requirement already satisfied: pypdf in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (3.16.4)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (2023.9.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (2.0.20)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (1.5.8)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (3.8.1)\n",
      "Requirement already satisfied: langchain>=0.0.303 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (0.0.314)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (0.5.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (8.2.3)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (0.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (1.5.3)\n",
      "Requirement already satisfied: urllib3<2 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (1.26.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (4.7.1)\n",
      "Requirement already satisfied: openai>=0.26.4 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (0.28.0)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from llama_index==0.8.48) (0.5.14)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: scipy in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx) (0.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->llama_index==0.8.48) (3.20.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx) (3.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama_index==0.8.48) (2.3.0)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama_index==0.8.48) (0.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama_index==0.8.48) (3.8.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama_index==0.8.48) (1.33)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain>=0.0.303->llama_index==0.8.48) (4.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index==0.8.48) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama_index==0.8.48) (8.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index==0.8.48) (2.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama_index==0.8.48) (0.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama_index==0.8.48) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->llama_index==0.8.48) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.48) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.48) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.48) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.48) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama_index==0.8.48) (1.9.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama_index==0.8.48) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.303->llama_index==0.8.48) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.303->llama_index==0.8.48) (2.6.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama_index==0.8.48) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wglantz\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index==0.8.48 pypdf sentence-transformers transformers httpx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79b9f3",
   "metadata": {},
   "source": [
    "## Use Inference embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de89ab",
   "metadata": {},
   "source": [
    "### Define LLM gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe006ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-############\"\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# define LLM\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a31c1",
   "metadata": {},
   "source": [
    "### Define Inference embedding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28665517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import TextEmbeddingsInference\n",
    "\n",
    "embed_model = TextEmbeddingsInference(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "    base_url = \"http://127.0.0.1:8080\",\n",
    "    #base_url = \"http://ec2-##-##-##-##.compute-1.amazonaws.com:8080\",\n",
    "    timeout=60,  # timeout in seconds\n",
    "    embed_batch_size=10,  # batch size for embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508eda9",
   "metadata": {},
   "source": [
    "### Define service_context, load doc, parse nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e5d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model, chunk_size=256, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938ee71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n",
      "loaded nodes with 14 nodes\n"
     ]
    }
   ],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.node_parser.extractors import (\n",
    "    MetadataExtractor,\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.text_splitter import TokenTextSplitter\n",
    "from llama_index import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "loader = WikipediaReader()\n",
    "documents = loader.load_data(pages=['Paleolithic diet'], auto_suggest=False)\n",
    "print(f'Loaded {len(documents)} documents')\n",
    "\n",
    "# #construct text splitter to split texts into chunks for processing\n",
    "text_splitter = TokenTextSplitter(separator=\" \", chunk_size=256, chunk_overlap=20)\n",
    "\n",
    "#create node parser to parse nodes from document\n",
    "node_parser = SimpleNodeParser(text_splitter=text_splitter)\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "print(f\"loaded nodes with {len(nodes)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f16a63",
   "metadata": {},
   "source": [
    "### Construct index and query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0fb544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be40c98ba15b46b48f51e4d9b727da11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following the paleolithic diet may potentially lead to weight loss and fat loss, as well as increased satiety from the foods typically eaten. However, it is important to note that there may also be potential nutritional deficiencies, such as those of vitamin D and calcium, which could compromise bone health. Additionally, there is a risk of ingesting toxins from high fish consumption.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    service_context=service_context,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\"What are some potential health improvements that may result from following the paleolithic diet?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b68a05",
   "metadata": {},
   "source": [
    "## Use OpenAI embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4d104",
   "metadata": {},
   "source": [
    "### Build index and query engine with OpenAI embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1a3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "\n",
    "service_context_openai = ServiceContext.from_defaults(llm=llm, embed_model=OpenAIEmbedding(), chunk_size=256, chunk_overlap=20)\n",
    "\n",
    "index_openai = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    service_context=service_context_openai\n",
    ")\n",
    "query_engine_openai = index_openai.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649639a",
   "metadata": {},
   "source": [
    "## Applying EDD (Eval-Driven Development) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de420074",
   "metadata": {},
   "source": [
    "### Generate question dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8602f72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What did John Harvey Kellogg support in terms of diet?\n",
      "2. What advancements in science have contributed to our understanding of early human diets?\n",
      "3. What is the proposed role of cooked starches in the paleolithic diet?\n",
      "4. Why is it difficult to devise an ideal diet by studying contemporary hunter-gatherers?\n",
      "5. What is the main limitation of the data used in Cordain's book?\n",
      "6. What is the emphasis of Loren Cordain's version of the paleolithic diet?\n",
      "7. When did the Paleolithic diet start to gain popularity?\n",
      "8. What was Richard Mackarness' stance on carbohydrates in his book \"Eat Fat and Grow Slim\"?\n",
      "9. What technological developments would have been dropped if humans were not nutritionally adaptable?\n",
      "10. How does the Paleolithic diet avoid food processing?\n",
      "11. What are some of the key differences between the Paleolithic diet and modern diets?\n",
      "12. According to Walter L. Voegtlin, what was the main component of the Stone Age diet?\n",
      "13. How do modern domesticated plants and animals differ from their Paleolithic ancestors?\n",
      "14. How did Eaton and Konner argue that modern humans are biologically similar to their primitive ancestors?\n",
      "15. How does the level of physical activity differ between modern hunter-gatherers and modern office workers?\n",
      "16. What is the impact of the paleolithic diet on bone health?\n",
      "17. How can historians trace the ideas behind the Paleolithic diet to the 19th century?\n",
      "18. How does the paleolithic diet compare to traditional ethnic diets in terms of health benefits?\n",
      "19. What are some lifestyle diseases that Eaton and Konner attributed to the mismatch between modern diet and human biology?\n",
      "20. According to the evolutionary discordance hypothesis, what is the cause of many chronic diseases in modern Western populations?\n",
      "21. Can the paleolithic diet be considered an effective treatment for inflammatory bowel disease?\n",
      "22. Based on the context information, what can be concluded about the long-term effects of the paleolithic diet on cardiovascular health?\n",
      "23. How do the animal-derived calorie percentages vary among different hunter-gatherer populations?\n",
      "24. Which specific hunter-gatherer group had their diet recorded for only a single month?\n",
      "25. How does the Human Timeline at the Smithsonian, National Museum of Natural History contribute to the educational value of the museum?\n",
      "26. How does the Human Timeline at the Smithsonian, National Museum of Natural History showcase the evolution of human civilization?\n",
      "27. What are some potential risks associated with high fish consumption in the paleolithic diet?\n",
      "28. What is the relevance of the August 2016 date mentioned in the context information?\n",
      "29. According to Marlene Zuk, why is the idea that our genetic makeup matches that of our ancestors misconceived?\n",
      "30. What is the Paleolithic diet and what foods does it typically include?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.evaluation import DatasetGenerator\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "question_dataset = []\n",
    "if os.path.exists(\"question_dataset.txt\"):\n",
    "    with open(\"question_dataset.txt\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            question_dataset.append(line.strip())\n",
    "else:\n",
    "    # generate questions\n",
    "    data_generator = DatasetGenerator.from_documents(nodes)\n",
    "    generated_questions = data_generator.generate_questions_from_nodes(num=30)\n",
    "    print(f\"Generated {len(generated_questions)} questions.\")\n",
    "\n",
    "    question_dataset.extend(generated_questions)\n",
    "    \n",
    "    # save the questions into a txt file\n",
    "    with open(\"question_dataset.txt\", \"w\") as f:\n",
    "        for question in question_dataset:\n",
    "            f.write(f\"{question.strip()}\\n\")\n",
    "\n",
    "for i, question in enumerate(question_dataset, start=1):\n",
    "    print(f\"{i}. {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183b613",
   "metadata": {},
   "source": [
    "### Define evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4355b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import FaithfulnessEvaluator, RelevancyEvaluator\n",
    "\n",
    "# use gpt-4 to evaluate\n",
    "gpt4_service_context = ServiceContext.from_defaults(llm=OpenAI(temperature=0.1, llm=\"gpt-4\"))\n",
    "\n",
    "faithfulness_gpt4 = FaithfulnessEvaluator(service_context=gpt4_service_context)\n",
    "relevancy_gpt4 = RelevancyEvaluator(service_context=gpt4_service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24853ea6",
   "metadata": {},
   "source": [
    "### Define BatchEvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823aa675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import BatchEvalRunner\n",
    "\n",
    "runner = BatchEvalRunner(\n",
    "    {\"faithfulness\": faithfulness_gpt4, \"relevancy\": relevancy_gpt4},\n",
    "    workers=4,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "def get_eval_results(key, eval_results):\n",
    "    results = eval_results[key]\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        if result.passing:\n",
    "            correct += 1\n",
    "    score = correct / len(results)\n",
    "    print(f\"{key} Correct: {correct}. Score: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e87ce",
   "metadata": {},
   "source": [
    "### Evaluate OpenAI embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbb24383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.36it/s]\n",
      "100%|██████████| 60/60 [00:09<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "faithfulness Correct: 24. Score: 0.8\n",
      "relevancy Correct: 28. Score: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine_openai, queries=question_dataset\n",
    ")\n",
    "\n",
    "print(\"------------------\")\n",
    "score = get_eval_results(\"faithfulness\", eval_results)\n",
    "score = get_eval_results(\"relevancy\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784323ee",
   "metadata": {},
   "source": [
    "### Evaluate Inference server embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77db96c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.37it/s]\n",
      "100%|██████████| 60/60 [00:08<00:00,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "faithfulness Correct: 25. Score: 0.8333333333333334\n",
      "relevancy Correct: 28. Score: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine, queries=question_dataset\n",
    ")\n",
    "\n",
    "print(\"------------------\")\n",
    "score = get_eval_results(\"faithfulness\", eval_results)\n",
    "score = get_eval_results(\"relevancy\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378894d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
